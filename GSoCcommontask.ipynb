{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2cA6tqxa6_L0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import h5py\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_electron = \"/ElectronG.hdf5\"\n",
        "file_photon = \"/PhotonG.hdf5\"\n",
        "\n",
        "\n",
        "with h5py.File(file_electron, \"r\") as f1:\n",
        "    X_elec = np.array(f1['X'][:])\n",
        "    y_elec = np.array(f1['y'][:])\n",
        "with h5py.File(file_photon, \"r\") as f2:\n",
        "    X_phot = np.array(f2['X'][:])\n",
        "    y_phot = np.array(f2['y'][:])"
      ],
      "metadata": {
        "id": "mCTMeG_rBupO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_elec.shape)\n",
        "print(X_phot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIbdq7HQB0TS",
        "outputId": "c14307a5-48c0-4c1e-cad6-22a24c9482f9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(249000, 32, 32, 2)\n",
            "(249000, 32, 32, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.append(X_elec, X_phot, axis=0)\n",
        "y = np.append(y_elec, y_phot)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BubYCyN_DLfd",
        "outputId": "e3f20cf5-05d8-4a10-9a14-154d118e9760"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(498000, 32, 32, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.swapaxes(X, 3,1) # Convenience of pytorch\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0pl4hevDORS",
        "outputId": "af034d06-71ee-46c7-96f3-ee81128ab1af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(498000, 2, 32, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.as_tensor(y)"
      ],
      "metadata": {
        "id": "B6KrOPrNDQbN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.from_numpy(X)"
      ],
      "metadata": {
        "id": "HpVnAjKEDS6I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.utils.data.TensorDataset(X, y)"
      ],
      "metadata": {
        "id": "qp6DxhcmDU_U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,val_data = torch.utils.data.random_split(dataset,[int(len(dataset)*0.8),int(len(dataset)*0.2)])"
      ],
      "metadata": {
        "id": "gTFt3bVTDYwR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torch.utils.data.DataLoader(train_data, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)\n",
        "valset = torch.utils.data.DataLoader(val_data, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "fyqNnNMQDcZm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Residual Block with Skip Connections\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Skip connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += identity  # Add skip connection\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# ResNet-15 Model\n",
        "class ResNet15(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ResNet15, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Residual Block 1\n",
        "        self.layer1 = self._make_layer(64, 64, num_blocks=2)\n",
        "        # Residual Block 2\n",
        "        self.layer2 = self._make_layer(64, 128, num_blocks=2, stride=2)\n",
        "        # Residual Block 3\n",
        "        self.layer3 = self._make_layer(128, 256, num_blocks=2, stride=2)\n",
        "        # Residual Block 4\n",
        "        self.layer4 = self._make_layer(256, 512, num_blocks=2, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Focal Loss Class\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=0.25):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
        "        p_t = torch.exp(-ce_loss)  # Probabilities of the correct class\n",
        "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = ResNet15(num_classes=2)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = FocalLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "# Learning Rate Scheduler (Cosine Annealing)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(25):\n",
        "    running_loss = 0.0\n",
        "    val_loss = 0.0\n",
        "    all_y_true = torch.zeros(0, dtype=torch.long, device=device)\n",
        "    all_y_pred = torch.zeros(0, dtype=torch.long, device=device)\n",
        "    all_y_true_val = torch.zeros(0, dtype=torch.long, device=device)\n",
        "    all_y_pred_val = torch.zeros(0, dtype=torch.long, device=device)\n",
        "\n",
        "    model.train()  # Set model to training mode\n",
        "    for i, data in enumerate(trainset, 0):\n",
        "        X, y = data\n",
        "        if torch.cuda.is_available():\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        preds = outputs\n",
        "        preds = preds.detach()\n",
        "        _, preds = torch.max(preds, 1)\n",
        "\n",
        "        # Concatenate true labels and predictions\n",
        "        all_y_true = torch.cat((all_y_true, y.view(-1)))\n",
        "        all_y_pred = torch.cat((all_y_pred, preds.view(-1)))\n",
        "\n",
        "        loss = criterion(outputs, y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:\n",
        "            auc_score = roc_auc_score(all_y_true.cpu().numpy(), all_y_pred.cpu().numpy())\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 500:.3f} auc_score_train: {auc_score}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Step the learning rate scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Validation Loop\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for j, data in enumerate(valset, 0):\n",
        "            X_val, y_val = data\n",
        "            if torch.cuda.is_available():\n",
        "                X_val = X_val.cuda()\n",
        "                y_val = y_val.cuda()\n",
        "\n",
        "            val_outputs = model(X_val)\n",
        "            loss_val = criterion(val_outputs, y_val.long())\n",
        "\n",
        "            _, val_preds = torch.max(val_outputs, 1)\n",
        "\n",
        "            all_y_true_val = torch.cat((all_y_true_val, y_val.view(-1)))\n",
        "            all_y_pred_val = torch.cat((all_y_pred_val, val_preds.view(-1)))\n",
        "\n",
        "            val_loss += loss_val.item()\n",
        "\n",
        "    auc_score_val = roc_auc_score(all_y_true_val.cpu().numpy(), all_y_pred_val.cpu().numpy())\n",
        "    print(f'val_loss: {val_loss / j:.3f} auc_score_val: {auc_score_val}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjXCZWRyGqGS",
        "outputId": "b05997a7-c505-4978-efcd-54164fb9515b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   500] loss: 0.043 auc_score_train: 0.6103598057629804\n",
            "[1,  1000] loss: 0.040 auc_score_train: 0.6230494841565468\n",
            "[1,  1500] loss: 0.039 auc_score_train: 0.6356545488863681\n",
            "val_loss: 0.040 auc_score_val: 0.6453792292147739\n",
            "[2,   500] loss: 0.038 auc_score_train: 0.6843034482250739\n",
            "[2,  1000] loss: 0.037 auc_score_train: 0.6897033718333743\n",
            "[2,  1500] loss: 0.037 auc_score_train: 0.6940015462506525\n",
            "val_loss: 0.039 auc_score_val: 0.6753297768086768\n",
            "[3,   500] loss: 0.036 auc_score_train: 0.708283987522305\n",
            "[3,  1000] loss: 0.036 auc_score_train: 0.710052619259536\n",
            "[3,  1500] loss: 0.036 auc_score_train: 0.711585176382536\n",
            "val_loss: 0.036 auc_score_val: 0.7139051881622035\n",
            "[4,   500] loss: 0.036 auc_score_train: 0.7157151141479\n",
            "[4,  1000] loss: 0.036 auc_score_train: 0.7158256576064843\n",
            "[4,  1500] loss: 0.036 auc_score_train: 0.7163601800815206\n",
            "val_loss: 0.036 auc_score_val: 0.7162618995799862\n",
            "[5,   500] loss: 0.036 auc_score_train: 0.7192093498593334\n",
            "[5,  1000] loss: 0.036 auc_score_train: 0.7187571562504473\n",
            "[5,  1500] loss: 0.036 auc_score_train: 0.7192942999982455\n",
            "val_loss: 0.037 auc_score_val: 0.7079886025429689\n",
            "[6,   500] loss: 0.036 auc_score_train: 0.7187662812510174\n",
            "[6,  1000] loss: 0.035 auc_score_train: 0.7201914138238882\n",
            "[6,  1500] loss: 0.035 auc_score_train: 0.721035883513161\n",
            "val_loss: 0.037 auc_score_val: 0.7111037245724929\n",
            "[7,   500] loss: 0.036 auc_score_train: 0.7208123155963797\n",
            "[7,  1000] loss: 0.035 auc_score_train: 0.7216034491924976\n",
            "[7,  1500] loss: 0.036 auc_score_train: 0.7218588001154631\n",
            "val_loss: 0.038 auc_score_val: 0.6869695109274956\n",
            "[8,   500] loss: 0.035 auc_score_train: 0.724054997006746\n",
            "[8,  1000] loss: 0.035 auc_score_train: 0.7241002817521639\n",
            "[8,  1500] loss: 0.035 auc_score_train: 0.7232294273434684\n",
            "val_loss: 0.036 auc_score_val: 0.7149268973096445\n",
            "[9,   500] loss: 0.035 auc_score_train: 0.7248569455814164\n",
            "[9,  1000] loss: 0.035 auc_score_train: 0.7242473850659124\n",
            "[9,  1500] loss: 0.035 auc_score_train: 0.7240906105913849\n",
            "val_loss: 0.036 auc_score_val: 0.7096754757650678\n",
            "[10,   500] loss: 0.035 auc_score_train: 0.7243912579159851\n",
            "[10,  1000] loss: 0.035 auc_score_train: 0.7237749229770444\n",
            "[10,  1500] loss: 0.035 auc_score_train: 0.7244136495064333\n",
            "val_loss: 0.036 auc_score_val: 0.72358029389269\n",
            "[11,   500] loss: 0.035 auc_score_train: 0.7238142652606984\n",
            "[11,  1000] loss: 0.035 auc_score_train: 0.7245152661790161\n",
            "[11,  1500] loss: 0.035 auc_score_train: 0.7247280244195683\n",
            "val_loss: 0.036 auc_score_val: 0.7159248723495311\n",
            "[12,   500] loss: 0.035 auc_score_train: 0.7266777770532098\n",
            "[12,  1000] loss: 0.035 auc_score_train: 0.7263637604093964\n",
            "[12,  1500] loss: 0.035 auc_score_train: 0.7265369078797859\n",
            "val_loss: 0.038 auc_score_val: 0.7021585377587201\n",
            "[13,   500] loss: 0.035 auc_score_train: 0.727403755553257\n",
            "[13,  1000] loss: 0.035 auc_score_train: 0.7268383757811013\n",
            "[13,  1500] loss: 0.035 auc_score_train: 0.7265482655854706\n",
            "val_loss: 0.036 auc_score_val: 0.7176441118033152\n",
            "[14,   500] loss: 0.035 auc_score_train: 0.7263686929879479\n",
            "[14,  1000] loss: 0.035 auc_score_train: 0.7269882278826254\n",
            "[14,  1500] loss: 0.035 auc_score_train: 0.7273563905118576\n",
            "val_loss: 0.035 auc_score_val: 0.7229441525532074\n",
            "[15,   500] loss: 0.035 auc_score_train: 0.7276682375350809\n",
            "[15,  1000] loss: 0.035 auc_score_train: 0.7281042422496931\n",
            "[15,  1500] loss: 0.035 auc_score_train: 0.7272140487457539\n",
            "val_loss: 0.035 auc_score_val: 0.7240078912904641\n",
            "[16,   500] loss: 0.035 auc_score_train: 0.7274633341154056\n",
            "[16,  1000] loss: 0.035 auc_score_train: 0.7277560753916825\n",
            "[16,  1500] loss: 0.035 auc_score_train: 0.7278771992991505\n",
            "val_loss: 0.036 auc_score_val: 0.7214977249955807\n",
            "[17,   500] loss: 0.035 auc_score_train: 0.7288699953886765\n",
            "[17,  1000] loss: 0.035 auc_score_train: 0.7276441041547163\n",
            "[17,  1500] loss: 0.035 auc_score_train: 0.7281699208496606\n",
            "val_loss: 0.037 auc_score_val: 0.6968723064719837\n",
            "[18,   500] loss: 0.035 auc_score_train: 0.7270679706135391\n",
            "[18,  1000] loss: 0.035 auc_score_train: 0.7292205513687937\n",
            "[18,  1500] loss: 0.035 auc_score_train: 0.72929122698542\n",
            "val_loss: 0.037 auc_score_val: 0.7174753976871664\n",
            "[19,   500] loss: 0.035 auc_score_train: 0.7279442040630333\n",
            "[19,  1000] loss: 0.035 auc_score_train: 0.7284742466808262\n",
            "[19,  1500] loss: 0.035 auc_score_train: 0.7292943795720067\n",
            "val_loss: 0.037 auc_score_val: 0.7066928065191524\n",
            "[20,   500] loss: 0.035 auc_score_train: 0.7309104404339978\n",
            "[20,  1000] loss: 0.035 auc_score_train: 0.7304485096583881\n",
            "[20,  1500] loss: 0.035 auc_score_train: 0.7297581116699321\n",
            "val_loss: 0.036 auc_score_val: 0.7230601237377012\n",
            "[21,   500] loss: 0.035 auc_score_train: 0.7326711523653922\n",
            "[21,  1000] loss: 0.035 auc_score_train: 0.7310245825345354\n",
            "[21,  1500] loss: 0.035 auc_score_train: 0.7307038764946533\n",
            "val_loss: 0.040 auc_score_val: 0.6272655913094001\n",
            "[22,   500] loss: 0.035 auc_score_train: 0.7306080869129312\n",
            "[22,  1000] loss: 0.035 auc_score_train: 0.7310859032614048\n",
            "[22,  1500] loss: 0.035 auc_score_train: 0.7315955695688737\n",
            "val_loss: 0.035 auc_score_val: 0.7310733387213707\n",
            "[23,   500] loss: 0.035 auc_score_train: 0.7324180920487481\n",
            "[23,  1000] loss: 0.035 auc_score_train: 0.7323299382071287\n",
            "[23,  1500] loss: 0.035 auc_score_train: 0.7316964669845262\n",
            "val_loss: 0.037 auc_score_val: 0.716335628879571\n",
            "[24,   500] loss: 0.035 auc_score_train: 0.7331024404387237\n",
            "[24,  1000] loss: 0.035 auc_score_train: 0.7310751771524934\n",
            "[24,  1500] loss: 0.035 auc_score_train: 0.7319793219487513\n",
            "val_loss: 0.035 auc_score_val: 0.7278279527855664\n",
            "[25,   500] loss: 0.035 auc_score_train: 0.7326398899322618\n",
            "[25,  1000] loss: 0.035 auc_score_train: 0.7331604877093334\n",
            "[25,  1500] loss: 0.035 auc_score_train: 0.7329677781145568\n",
            "val_loss: 0.035 auc_score_val: 0.730562275481533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model (including architecture and weights)\n",
        "torch.save(model, 'resnet15_model.pth')\n"
      ],
      "metadata": {
        "id": "LEgI66tSP3ba"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('resnet15_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "E-Q9D2huQEVr",
        "outputId": "1580bd02-1ea1-4419-d51b-94a09a599b1c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f366f5b7-6986-495d-8ce9-5852c398c79c\", \"resnet15_model.pth\", 44770352)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}